#!/usr/bin/env python3
"""
å…¨é¢çš„é¡¹ç›®é‡æ„è„šæœ¬
å¤„ç†æ–‡ä»¶å‘½åè§„èŒƒåŒ–ã€ç¡¬ç¼–ç è·¯å¾„é—®é¢˜å’Œä»£ç é€‚åº”æ€§ä¿®æ”¹

ä½œè€…: AI Assistant
æ—¥æœŸ: 2024-11-30
"""

import os
import re
import json
import shutil
from pathlib import Path
from typing import Dict, List, Tuple, Set
from datetime import datetime


class ComprehensiveRefactor:
    """å…¨é¢çš„é¡¹ç›®é‡æ„å™¨"""
    
    def __init__(self, project_root: str = None):
        self.project_root = Path(project_root) if project_root else Path.cwd()
        self.log_file = self.project_root / f"refactor_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
        # æ–‡ä»¶é‡å‘½åæ˜ å°„
        self.file_rename_map = {}
        
        # ç¡¬ç¼–ç è·¯å¾„æ¨¡å¼
        self.hardcoded_patterns = [
            get_project_path()\']*',
            r'get_project_path()"\']*',
            r'r["\']C:\\\\Users\\\\[^"\']*["\']',
            r'r["\'][^"\']*TsyFSpectrumClassify[^"\']*["\']'
        ]
        
        # éœ€è¦è·³è¿‡çš„ç›®å½•
        self.skip_dirs = {'.git', '__pycache__', '.venv', 'venv', 'node_modules', 'backup_*'}
        
        # æ·±åº¦å­¦ä¹ é¡¹ç›®å‘½åè§„èŒƒ
        self.naming_rules = {
            'python_files': {
                'pattern': r'^[a-z][a-z0-9_]*\.py$',
                'description': 'ä½¿ç”¨å°å†™å­—æ¯å’Œä¸‹åˆ’çº¿ï¼Œå¦‚: model_trainer.py'
            },
            'class_names': {
                'pattern': r'^[A-Z][a-zA-Z0-9]*$',
                'description': 'ä½¿ç”¨é©¼å³°å‘½åï¼Œå¦‚: ModelTrainer'
            },
            'function_names': {
                'pattern': r'^[a-z][a-z0-9_]*$',
                'description': 'ä½¿ç”¨å°å†™å­—æ¯å’Œä¸‹åˆ’çº¿ï¼Œå¦‚: train_model'
            },
            'constants': {
                'pattern': r'^[A-Z][A-Z0-9_]*$',
                'description': 'ä½¿ç”¨å¤§å†™å­—æ¯å’Œä¸‹åˆ’çº¿ï¼Œå¦‚: MAX_EPOCHS'
            }
        }
    
    def log(self, message: str):
        """è®°å½•æ—¥å¿—"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] {message}"
        print(log_entry)
        
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_entry + '\n')
    
    def analyze_naming_issues(self) -> Dict[str, List[str]]:
        """åˆ†ææ–‡ä»¶å‘½åé—®é¢˜"""
        self.log("ğŸ” åˆ†ææ–‡ä»¶å‘½åé—®é¢˜...")
        
        issues = {
            'irregular_python_files': [],
            'irregular_directories': [],
            'typos': [],
            'case_issues': []
        }
        
        # æ£€æŸ¥Pythonæ–‡ä»¶å‘½å
        for py_file in self.project_root.rglob("*.py"):
            if any(skip in str(py_file) for skip in self.skip_dirs):
                continue
                
            filename = py_file.name
            
            # æ£€æŸ¥ä¸è§„èŒƒçš„å‘½å
            if not re.match(self.naming_rules['python_files']['pattern'], filename):
                issues['irregular_python_files'].append(str(py_file.relative_to(self.project_root)))
        
        # æ£€æŸ¥ç›®å½•å‘½å
        for directory in self.project_root.rglob("*"):
            if not directory.is_dir():
                continue
            if any(skip in str(directory) for skip in self.skip_dirs):
                continue
                
            dir_name = directory.name
            
            # æ£€æŸ¥æ‹¼å†™é”™è¯¯
            if 'classfication' in dir_name:
                issues['typos'].append(str(directory.relative_to(self.project_root)))
            
            # æ£€æŸ¥å¤§å°å†™é—®é¢˜
            if re.search(r'[A-Z]', dir_name) and dir_name not in ['README.md', 'LICENSE']:
                issues['case_issues'].append(str(directory.relative_to(self.project_root)))
        
        # è¾“å‡ºåˆ†æç»“æœ
        self.log("\nğŸ“Š å‘½åé—®é¢˜åˆ†æç»“æœ:")
        for category, files in issues.items():
            if files:
                self.log(f"  {category}: {len(files)} ä¸ªé—®é¢˜")
                for file in files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    self.log(f"    - {file}")
                if len(files) > 5:
                    self.log(f"    ... è¿˜æœ‰ {len(files) - 5} ä¸ª")
        
        return issues
    
    def generate_rename_plan(self, issues: Dict[str, List[str]]) -> Dict[str, str]:
        """ç”Ÿæˆé‡å‘½åè®¡åˆ’"""
        self.log("\nğŸ“‹ ç”Ÿæˆé‡å‘½åè®¡åˆ’...")
        
        rename_plan = {}
        
        # å¤„ç†ä¸è§„èŒƒçš„Pythonæ–‡ä»¶
        for file_path in issues['irregular_python_files']:
            old_path = self.project_root / file_path
            filename = old_path.name
            
            # è§„èŒƒåŒ–æ–‡ä»¶å
            new_filename = self._normalize_filename(filename)
            if new_filename != filename:
                new_path = old_path.parent / new_filename
                rename_plan[str(old_path)] = str(new_path)
        
        # å¤„ç†æ‹¼å†™é”™è¯¯çš„ç›®å½•
        for dir_path in issues['typos']:
            old_path = self.project_root / dir_path
            if 'classfication' in old_path.name:
                new_name = old_path.name.replace('classfication', 'classification')
                new_path = old_path.parent / new_name
                rename_plan[str(old_path)] = str(new_path)
        
        self.log(f"  ç”Ÿæˆäº† {len(rename_plan)} ä¸ªé‡å‘½åæ“ä½œ")
        return rename_plan
    
    def _normalize_filename(self, filename: str) -> str:
        """è§„èŒƒåŒ–æ–‡ä»¶å"""
        name, ext = os.path.splitext(filename)
        
        # å¤„ç†å¸¸è§çš„ä¸è§„èŒƒå‘½å
        name = name.replace('-', '_')  # è¿å­—ç¬¦æ”¹ä¸ºä¸‹åˆ’çº¿
        name = re.sub(r'(\d+)D_', r'\1d_', name)  # 2D_CNN -> 2d_cnn
        name = re.sub(r'([A-Z]+)', lambda m: m.group(1).lower(), name)  # å¤§å†™æ”¹å°å†™
        name = re.sub(r'_+', '_', name)  # å¤šä¸ªä¸‹åˆ’çº¿åˆå¹¶
        name = name.strip('_')  # å»é™¤é¦–å°¾ä¸‹åˆ’çº¿
        
        # ç‰¹æ®Šå¤„ç†
        special_cases = {
            'read)mat': 'read_mat',  # ä¿®å¤æ‹¬å·é”™è¯¯
            '2d_cnn1': 'cnn_2d_v1',
            '1d_cnn': 'cnn_1d',
            'lstm1': 'lstm_v1',
            'rf1': 'random_forest_v1',
            'knn1': 'knn_v1',
            'transformer1': 'transformer_v1'
        }
        
        if name in special_cases:
            name = special_cases[name]
        
        return name + ext
    
    def scan_hardcoded_paths(self) -> Dict[str, List[Tuple[str, int, str]]]:
        """æ‰«æç¡¬ç¼–ç è·¯å¾„"""
        self.log("\nğŸ” æ‰«æç¡¬ç¼–ç è·¯å¾„...")
        
        hardcoded_files = {}
        
        for file_path in self.project_root.rglob("*"):
            if not file_path.is_file():
                continue
            if file_path.suffix not in ['.py', '.json', '.md', '.txt']:
                continue
            if any(skip in str(file_path) for skip in self.skip_dirs):
                continue
            
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                matches = []
                for line_num, line in enumerate(content.split('\n'), 1):
                    for pattern in self.hardcoded_patterns:
                        for match in re.finditer(pattern, line):
                            matches.append((str(file_path.relative_to(self.project_root)), 
                                          line_num, match.group()))
                
                if matches:
                    hardcoded_files[str(file_path.relative_to(self.project_root))] = matches
                    
            except Exception as e:
                self.log(f"  âš ï¸ æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
        
        self.log(f"  å‘ç° {len(hardcoded_files)} ä¸ªæ–‡ä»¶åŒ…å«ç¡¬ç¼–ç è·¯å¾„")
        return hardcoded_files
    
    def create_path_config_system(self):
        """åˆ›å»ºè·¯å¾„é…ç½®ç³»ç»Ÿ"""
        self.log("\nğŸ› ï¸ åˆ›å»ºè·¯å¾„é…ç½®ç³»ç»Ÿ...")
        
        # åˆ›å»ºè·¯å¾„é…ç½®æ–‡ä»¶
        path_config = {
            "project_root": ".",
            "data": {
                "raw": "data/raw",
                "processed": "data/processed", 
                "target": "data/target"
            },
            "models": {
                "classification": "models/classification",
                "regression": "models/regression"
            },
            "results": {
                "classification": "results/classification",
                "regression": "results/regression"
            },
            "configs": {
                "main": "configs/main",
                "classification": "configs/classification",
                "regression": "configs/regression",
                "preprocessing": "configs/preprocessing"
            },
            "logs": "logs",
            "notebooks": "notebooks"
        }
        
        config_path = self.project_root / "configs" / "paths.json"
        config_path.parent.mkdir(exist_ok=True)
        
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(path_config, f, indent=2, ensure_ascii=False)
        
        # åˆ›å»ºè·¯å¾„ç®¡ç†å·¥å…·
        path_manager_code = '''"""
è·¯å¾„ç®¡ç†å·¥å…·
æä¾›ç»Ÿä¸€çš„è·¯å¾„ç®¡ç†æ¥å£ï¼Œé¿å…ç¡¬ç¼–ç è·¯å¾„
"""

import json
import os
from pathlib import Path
from typing import Dict, Any


class PathManager:
    """è·¯å¾„ç®¡ç†å™¨"""
    
    def __init__(self, config_path: str = None):
        if config_path is None:
            # è‡ªåŠ¨æŸ¥æ‰¾é…ç½®æ–‡ä»¶
            current_dir = Path(__file__).parent
            while current_dir != current_dir.parent:
                config_file = current_dir / "configs" / "paths.json"
                if config_file.exists():
                    config_path = str(config_file)
                    break
                current_dir = current_dir.parent
            
            if config_path is None:
                raise FileNotFoundError("æœªæ‰¾åˆ°è·¯å¾„é…ç½®æ–‡ä»¶ paths.json")
        
        self.config_path = Path(config_path)
        self.project_root = self.config_path.parent.parent
        self._load_config()
    
    def _load_config(self):
        """åŠ è½½é…ç½®"""
        with open(self.config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
    
    def get_path(self, *keys) -> Path:
        """è·å–è·¯å¾„"""
        current = self.config
        for key in keys:
            if isinstance(current, dict) and key in current:
                current = current[key]
            else:
                raise KeyError(f"è·¯å¾„é…ç½®ä¸­æœªæ‰¾åˆ°: {'.'.join(keys)}")
        
        if isinstance(current, str):
            path = self.project_root / current
            path.mkdir(parents=True, exist_ok=True)
            return path
        else:
            raise ValueError(f"è·¯å¾„é…ç½®å€¼å¿…é¡»æ˜¯å­—ç¬¦ä¸²: {'.'.join(keys)}")
    
    def get_data_path(self, data_type: str = "raw") -> Path:
        """è·å–æ•°æ®è·¯å¾„"""
        return self.get_path("data", data_type)
    
    def get_model_path(self, model_type: str) -> Path:
        """è·å–æ¨¡å‹è·¯å¾„"""
        return self.get_path("models", model_type)
    
    def get_result_path(self, result_type: str) -> Path:
        """è·å–ç»“æœè·¯å¾„"""
        return self.get_path("results", result_type)
    
    def get_config_path(self, config_type: str) -> Path:
        """è·å–é…ç½®è·¯å¾„"""
        return self.get_path("configs", config_type)
    
    def get_log_path(self) -> Path:
        """è·å–æ—¥å¿—è·¯å¾„"""
        return self.get_path("logs")


# å…¨å±€è·¯å¾„ç®¡ç†å™¨å®ä¾‹
try:
    path_manager = PathManager()
except FileNotFoundError:
    path_manager = None
    print("è­¦å‘Š: æœªæ‰¾åˆ°è·¯å¾„é…ç½®æ–‡ä»¶ï¼Œè¯·ç¡®ä¿ configs/paths.json å­˜åœ¨")


def get_project_path(*keys) -> Path:
    """ä¾¿æ·å‡½æ•°ï¼šè·å–é¡¹ç›®è·¯å¾„"""
    if path_manager is None:
        raise RuntimeError("è·¯å¾„ç®¡ç†å™¨æœªåˆå§‹åŒ–")
    return path_manager.get_path(*keys)


def get_data_path(data_type: str = "raw") -> Path:
    """ä¾¿æ·å‡½æ•°ï¼šè·å–æ•°æ®è·¯å¾„"""
    if path_manager is None:
        raise RuntimeError("è·¯å¾„ç®¡ç†å™¨æœªåˆå§‹åŒ–")
    return path_manager.get_data_path(data_type)
'''
        
        path_manager_file = self.project_root / "src" / "utils" / "path_manager.py"
        with open(path_manager_file, 'w', encoding='utf-8') as f:
            f.write(path_manager_code)
        
        self.log(f"  âœ… åˆ›å»ºè·¯å¾„é…ç½®æ–‡ä»¶: {config_path}")
        self.log(f"  âœ… åˆ›å»ºè·¯å¾„ç®¡ç†å™¨: {path_manager_file}")
    
    def fix_hardcoded_paths(self, hardcoded_files: Dict[str, List[Tuple[str, int, str]]]):
        """ä¿®å¤ç¡¬ç¼–ç è·¯å¾„"""
        self.log("\nğŸ”§ ä¿®å¤ç¡¬ç¼–ç è·¯å¾„...")
        
        fixed_count = 0
        
        for file_path, matches in hardcoded_files.items():
            full_path = self.project_root / file_path
            
            try:
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                original_content = content
                
                # æ›¿æ¢ç¡¬ç¼–ç è·¯å¾„
                for pattern in self.hardcoded_patterns:
                    content = re.sub(pattern, self._generate_relative_path, content)
                
                # å¦‚æœå†…å®¹æœ‰å˜åŒ–ï¼Œå†™å›æ–‡ä»¶
                if content != original_content:
                    with open(full_path, 'w', encoding='utf-8') as f:
                        f.write(content)
                    
                    fixed_count += 1
                    self.log(f"  âœ… ä¿®å¤æ–‡ä»¶: {file_path}")
                    
            except Exception as e:
                self.log(f"  âŒ ä¿®å¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        self.log(f"  ä¿®å¤äº† {fixed_count} ä¸ªæ–‡ä»¶")
    
    def _generate_relative_path(self, match) -> str:
        """ç”Ÿæˆç›¸å¯¹è·¯å¾„æ›¿æ¢"""
        path_str = match.group()
        
        # ç®€å•çš„è·¯å¾„æ›¿æ¢ç­–ç•¥
        if 'dataset' in path_str:
            return 'get_data_path("raw")'
        elif 'config' in path_str:
            return 'get_project_path("configs")'
        elif 'result' in path_str:
            return 'get_project_path("results")'
        else:
            return 'get_project_path()'
    
    def preview_changes(self, rename_plan: Dict[str, str], hardcoded_files: Dict):
        """é¢„è§ˆæ‰€æœ‰æ›´æ”¹"""
        self.log("\nğŸ‘€ é¢„è§ˆæ‰€æœ‰æ›´æ”¹:")
        self.log("="*60)
        
        self.log(f"\nğŸ“ æ–‡ä»¶é‡å‘½å ({len(rename_plan)} ä¸ª):")
        for old_path, new_path in list(rename_plan.items())[:10]:
            self.log(f"  {Path(old_path).name} â†’ {Path(new_path).name}")
        if len(rename_plan) > 10:
            self.log(f"  ... è¿˜æœ‰ {len(rename_plan) - 10} ä¸ªé‡å‘½åæ“ä½œ")
        
        self.log(f"\nğŸ”§ ç¡¬ç¼–ç è·¯å¾„ä¿®å¤ ({len(hardcoded_files)} ä¸ªæ–‡ä»¶):")
        for file_path in list(hardcoded_files.keys())[:10]:
            self.log(f"  {file_path}")
        if len(hardcoded_files) > 10:
            self.log(f"  ... è¿˜æœ‰ {len(hardcoded_files) - 10} ä¸ªæ–‡ä»¶")
        
        self.log("="*60)
    
    def execute_refactoring(self, rename_plan: Dict[str, str], hardcoded_files: Dict):
        """æ‰§è¡Œé‡æ„"""
        self.log("\nğŸš€ å¼€å§‹æ‰§è¡Œé‡æ„...")
        
        # 1. æ‰§è¡Œæ–‡ä»¶é‡å‘½å
        self.log("\nğŸ“ æ‰§è¡Œæ–‡ä»¶é‡å‘½å...")
        rename_success = 0
        for old_path, new_path in rename_plan.items():
            try:
                old_p = Path(old_path)
                new_p = Path(new_path)
                
                if old_p.exists():
                    new_p.parent.mkdir(parents=True, exist_ok=True)
                    shutil.move(str(old_p), str(new_p))
                    rename_success += 1
                    self.log(f"  âœ… {old_p.name} â†’ {new_p.name}")
                    
            except Exception as e:
                self.log(f"  âŒ é‡å‘½åå¤±è´¥ {old_path}: {e}")
        
        self.log(f"  é‡å‘½åæˆåŠŸ: {rename_success}/{len(rename_plan)}")
        
        # 2. ä¿®å¤ç¡¬ç¼–ç è·¯å¾„
        self.fix_hardcoded_paths(hardcoded_files)
        
        # 3. åˆ›å»ºè·¯å¾„é…ç½®ç³»ç»Ÿ
        self.create_path_config_system()
    
    def run_comprehensive_refactor(self):
        """è¿è¡Œå…¨é¢é‡æ„"""
        self.log("ğŸ¯ å¼€å§‹å…¨é¢é¡¹ç›®é‡æ„")
        self.log("="*60)
        
        try:
            # 1. åˆ†æå‘½åé—®é¢˜
            issues = self.analyze_naming_issues()
            
            # 2. ç”Ÿæˆé‡å‘½åè®¡åˆ’
            rename_plan = self.generate_rename_plan(issues)
            
            # 3. æ‰«æç¡¬ç¼–ç è·¯å¾„
            hardcoded_files = self.scan_hardcoded_paths()
            
            # 4. é¢„è§ˆæ›´æ”¹
            self.preview_changes(rename_plan, hardcoded_files)
            
            # 5. ç”¨æˆ·ç¡®è®¤
            print("\n" + "="*60)
            print("âš ï¸  å³å°†æ‰§è¡Œä»¥ä¸‹æ“ä½œ:")
            print(f"   - é‡å‘½å {len(rename_plan)} ä¸ªæ–‡ä»¶/ç›®å½•")
            print(f"   - ä¿®å¤ {len(hardcoded_files)} ä¸ªæ–‡ä»¶ä¸­çš„ç¡¬ç¼–ç è·¯å¾„")
            print(f"   - åˆ›å»ºç»Ÿä¸€çš„è·¯å¾„ç®¡ç†ç³»ç»Ÿ")
            print("="*60)
            
            confirm = input("æ˜¯å¦ç»§ç»­æ‰§è¡Œé‡æ„? (y/N): ").strip().lower()
            if confirm in ['y', 'yes']:
                # 6. æ‰§è¡Œé‡æ„
                self.execute_refactoring(rename_plan, hardcoded_files)
                
                self.log("\nğŸ‰ é‡æ„å®Œæˆ!")
                self.log(f"ğŸ“„ è¯¦ç»†æ—¥å¿—: {self.log_file}")
            else:
                self.log("âŒ ç”¨æˆ·å–æ¶ˆäº†é‡æ„æ“ä½œ")
                
        except Exception as e:
            self.log(f"âŒ é‡æ„è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            raise


if __name__ == "__main__":
    refactor = ComprehensiveRefactor()
    refactor.run_comprehensive_refactor()
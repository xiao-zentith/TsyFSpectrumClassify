#!/usr/bin/env python3
"""
å¯¼å…¥è·¯å¾„æ›´æ–°è„šæœ¬
ç”¨äºé‡æ„åæ›´æ–°æ‰€æœ‰Pythonæ–‡ä»¶çš„importè¯­å¥
"""
import os
import re
from pathlib import Path
from typing import Dict, List, Tuple

class ImportUpdater:
    def __init__(self, project_root=None):
        self.project_root = Path(project_root) if project_root else Path.cwd()
        self.import_mapping = self.get_import_mapping()
        self.updated_files = []
        
    def get_import_mapping(self) -> Dict[str, str]:
        """å®šä¹‰å¯¼å…¥è·¯å¾„æ˜ å°„"""
        return {
            # Utilsæ¨¡å—æ˜ å°„
            'from src.utils.data_io.mat_reader import': 'from src.utils.data_io.mat_reader import',
            'from src.utils.data_io.matrix_reader import': 'from src.utils.data_io.matrix_reader import',
            'from src.utils.data_io.npz_reader import': 'from src.utils.data_io.npz_reader import',
            'from src.utils.data_io.data_loader import': 'from src.utils.data_io.data_loader import',
            'from src.utils.data_io.data_extractor import': 'from src.utils.data_io.data_extractor import',
            'from src.utils.data_io.mat_tool import': 'from src.utils.data_io.mat_tool import',
            'from src.utils.data_io.json_generator import': 'from src.utils.data_io.json_generator import',
            
            'from src.utils.visualization.spectrum_plotter import': 'from src.utils.visualization.spectrum_plotter import',
            'from src.utils.visualization.contour_plotter import': 'from src.utils.visualization.contour_plotter import',
            'from src.utils.visualization.radar_plotter import': 'from src.utils.visualization.radar_plotter import',
            'from src.utils.visualization.result_plotter import': 'from src.utils.visualization.result_plotter import',
            
            'from src.utils.metrics.similarity_calculator import': 'from src.utils.metrics.similarity_calculator import',
            'from src.utils.metrics.pearson_calculator import': 'from src.utils.metrics.pearson_calculator import',
            'from src.utils.metrics.cosine_similarity import': 'from src.utils.metrics.cosine_similarity import',
            
            'from src.utils.file_operations.batch_resizer import': 'from src.utils.file_operations.batch_resizer import',
            'from src.utils.file_operations.resizer import': 'from src.utils.file_operations.resizer import',
            'from src.utils.file_operations.json_merger import': 'from src.utils.file_operations.json_merger import',
            'from src.utils.file_operations.txt_to_xlsx import': 'from src.utils.file_operations.txt_to_xlsx import',
            
            # åˆ†ç±»æ¨¡å—æ˜ å°„
            'from src.classification.utils.image_dataset import': 'from src.classification.utils.image_dataset import',
            'from src.classification.utils.plot_utils import': 'from src.classification.utils.plot_utils import',
            'from src.classification.utils.matrix_reader import': 'from src.classification.utils.matrix_reader import',
            
            # å›å½’æ¨¡å—æ˜ å°„
            'from src.regression.training.custom_dataset import': 'from src.regression.training.custom_dataset import',
            'from src.regression.models.': 'from src.regression.models.',
            
            # é¢„å¤„ç†æ¨¡å—æ˜ å°„
            'from src.preprocessing.': 'from src.preprocessing.',
            
            # å¢å¼ºæ¨¡å—æ˜ å°„
            'from src.augmentation.': 'from src.augmentation.',
            
            # importè¯­å¥æ˜ å°„
            'import src.utils.': 'import src.utils.',
            'import src.classification.': 'import src.classification.',
            'import src.regression.': 'import src.regression.',
            'import src.preprocessing.': 'import src.preprocessing.',
            'import src.augmentation.': 'import src.augmentation.',
        }
    
    def find_python_files(self) -> List[Path]:
        """æŸ¥æ‰¾æ‰€æœ‰Pythonæ–‡ä»¶"""
        python_files = []
        for root, dirs, files in os.walk(self.project_root):
            # è·³è¿‡æŸäº›ç›®å½•
            dirs[:] = [d for d in dirs if d not in ['.git', '__pycache__', '.venv', 'venv']]
            
            for file in files:
                if file.endswith('.py'):
                    python_files.append(Path(root) / file)
        
        return python_files
    
    def update_file_imports(self, file_path: Path) -> bool:
        """æ›´æ–°å•ä¸ªæ–‡ä»¶çš„å¯¼å…¥è¯­å¥"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            updated = False
            
            # åº”ç”¨å¯¼å…¥æ˜ å°„
            for old_import, new_import in self.import_mapping.items():
                if old_import in content:
                    content = content.replace(old_import, new_import)
                    updated = True
            
            # å¦‚æœæœ‰æ›´æ–°ï¼Œå†™å›æ–‡ä»¶
            if updated:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                self.updated_files.append(str(file_path))
                print(f"âœ… æ›´æ–°: {file_path}")
                return True
            
            return False
            
        except Exception as e:
            print(f"âŒ æ›´æ–°å¤±è´¥ {file_path}: {str(e)}")
            return False
    
    def update_all_imports(self):
        """æ›´æ–°æ‰€æœ‰æ–‡ä»¶çš„å¯¼å…¥è¯­å¥"""
        print("å¼€å§‹æ›´æ–°å¯¼å…¥è·¯å¾„...")
        
        python_files = self.find_python_files()
        print(f"æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶")
        
        updated_count = 0
        for file_path in python_files:
            if self.update_file_imports(file_path):
                updated_count += 1
        
        print(f"\næ›´æ–°å®Œæˆ: {updated_count}/{len(python_files)} ä¸ªæ–‡ä»¶è¢«æ›´æ–°")
        
        if self.updated_files:
            print("\næ›´æ–°çš„æ–‡ä»¶åˆ—è¡¨:")
            for file_path in self.updated_files:
                print(f"  - {file_path}")
    
    def generate_import_report(self):
        """ç”Ÿæˆå¯¼å…¥æ›´æ–°æŠ¥å‘Š"""
        report_file = self.project_root / "import_update_report.txt"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("å¯¼å…¥è·¯å¾„æ›´æ–°æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"æ›´æ–°æ—¶é—´: {os.popen('date').read().strip()}\n")
            f.write(f"æ›´æ–°æ–‡ä»¶æ•°é‡: {len(self.updated_files)}\n\n")
            
            f.write("æ›´æ–°çš„æ–‡ä»¶åˆ—è¡¨:\n")
            for file_path in self.updated_files:
                f.write(f"  - {file_path}\n")
            
            f.write("\nåº”ç”¨çš„æ˜ å°„è§„åˆ™:\n")
            for old, new in self.import_mapping.items():
                f.write(f"  {old} -> {new}\n")
        
        print(f"ğŸ“ æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("å¯¼å…¥è·¯å¾„æ›´æ–°å·¥å…·")
    print("=" * 30)
    
    updater = ImportUpdater()
    
    try:
        updater.update_all_imports()
        updater.generate_import_report()
        print("\nâœ… å¯¼å…¥è·¯å¾„æ›´æ–°å®Œæˆ!")
        
    except Exception as e:
        print(f"\nâŒ æ›´æ–°è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        return 1
    
    return 0

if __name__ == "__main__":
    import sys
    sys.exit(main())
#!/usr/bin/env python3
"""
ä¿®å¤ç‰ˆæœ¬çš„é¡¹ç›®é‡æ„è„šæœ¬
è§£å†³æƒé™å’Œä¾èµ–é—®é¢˜
"""
import os
import shutil
import sys
from pathlib import Path
from datetime import datetime
import json

class FixedProjectRestructurer:
    def __init__(self, project_root=None):
        self.project_root = Path(project_root) if project_root else Path.cwd()
        # åœ¨é¡¹ç›®å†…éƒ¨åˆ›å»ºå¤‡ä»½ç›®å½•
        self.backup_dir = self.project_root / f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.log_file = self.project_root / "restructure.log"
        
    def log(self, message):
        """è®°å½•æ—¥å¿—"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_message = f"[{timestamp}] {message}"
        print(log_message)
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_message + '\n')
    
    def create_backup(self):
        """åˆ›å»ºé¡¹ç›®å¤‡ä»½ï¼ˆä»…ä»£ç æ–‡ä»¶ï¼Œä½¿ç”¨Pythonå†…ç½®åŠŸèƒ½ï¼‰"""
        self.log("å¼€å§‹åˆ›å»ºé¡¹ç›®å¤‡ä»½...")
        
        # è¦æ’é™¤çš„ç›®å½•å’Œæ–‡ä»¶
        exclude_dirs = {
            'dataset', 'dataset_classify', '.venv', '__pycache__', 
            'logs', 'results', 'dataset_result', '.git', '.idea'
        }
        exclude_extensions = {'.pyc', '.pyo', '.log'}
        
        try:
            self.backup_dir.mkdir(exist_ok=True)
            
            def should_exclude(path):
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ’é™¤çš„ç›®å½•
                for part in path.parts:
                    if part in exclude_dirs:
                        return True
                    # æ’é™¤æ‰€æœ‰ä»¥backup_å¼€å¤´çš„ç›®å½•
                    if part.startswith('backup_'):
                        return True
                # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
                if path.suffix in exclude_extensions:
                    return True
                return False
            
            # å¤åˆ¶æ–‡ä»¶
            copied_count = 0
            for item in self.project_root.rglob('*'):
                if item.is_file() and not should_exclude(item.relative_to(self.project_root)):
                    # è®¡ç®—ç›¸å¯¹è·¯å¾„
                    rel_path = item.relative_to(self.project_root)
                    dest_path = self.backup_dir / rel_path
                    
                    # åˆ›å»ºç›®æ ‡ç›®å½•
                    dest_path.parent.mkdir(parents=True, exist_ok=True)
                    
                    # å¤åˆ¶æ–‡ä»¶
                    shutil.copy2(item, dest_path)
                    copied_count += 1
            
            self.log(f"å¤‡ä»½åˆ›å»ºæˆåŠŸ: {self.backup_dir}")
            self.log(f"å…±å¤åˆ¶ {copied_count} ä¸ªæ–‡ä»¶")
            return True
            
        except Exception as e:
            self.log(f"å¤‡ä»½åˆ›å»ºå¼‚å¸¸: {str(e)}")
            return False
    
    def get_new_structure(self):
        """å®šä¹‰æ–°çš„ç›®å½•ç»“æ„"""
        return {
            'src': {
                'utils': {
                    'data_io': {},
                    'visualization': {},
                    'metrics': {},
                    'file_operations': {}
                },
                'classification': {
                    'models': {
                        'demo': {}
                    },
                    'utils': {}
                },
                'regression': {
                    'models': {},
                    'training': {},
                    'utils': {}
                },
                'augmentation': {},
                'preprocessing': {},
                'ui': {}
            },
            'notebooks': {
                'exploration': {},
                'experiments': {},
                'demos': {}
            },
            'tests': {
                'test_classification': {},
                'test_regression': {},
                'test_utils': {}
            },
            'scripts': {
                'training': {},
                'evaluation': {},
                'data_processing': {}
            },
            'configs': {},
            'docs': {}
        }
    
    def get_file_mapping(self):
        """å®šä¹‰æ–‡ä»¶æ˜ å°„å…³ç³»"""
        return {
            # å›å½’æ¨¡å—
            'regression/model/': 'src/regression/models/',
            'regression/training/': 'src/regression/training/',
            'regression/utils/': 'src/regression/utils/',
            'regression/run_training.py': 'scripts/training/run_regression_training.py',
            'regression/batch_run.py': 'scripts/training/batch_regression_run.py',
            
            # åˆ†ç±»æ¨¡å—
            'classfication/model/': 'src/classification/models/',
            'classfication/classify_model_demo/': 'src/classification/models/demo/',
            'classfication/Utils/': 'src/classification/utils/',
            
            # æ•°æ®å¢å¼º
            'augmentation/': 'src/augmentation/',
            
            # é¢„å¤„ç†
            'preprocess/': 'src/preprocessing/',
            
            # UI
            'UI_version/': 'src/ui/',
            
            # å·¥å…·ç±»
            'Utils/batch_resize.py': 'src/utils/file_operations/batch_resize.py',
            'Utils/batch_test.py': 'scripts/evaluation/batch_test.py',
            'Utils/compute_pearson.py': 'src/utils/metrics/compute_pearson.py',
            'Utils/compute_relative_error.py': 'src/utils/metrics/compute_relative_error.py',
            'Utils/compute_similarity.py': 'src/utils/metrics/compute_similarity.py',
            'Utils/cosine_similarity.py': 'src/utils/metrics/cosine_similarity.py',
            'Utils/draw_2D_spectrum.py': 'src/utils/visualization/draw_2d_spectrum.py',
            'Utils/draw_2D_spectrum_xlsx.py': 'src/utils/visualization/draw_2d_spectrum_xlsx.py',
            'Utils/draw_contour.py': 'src/utils/visualization/draw_contour.py',
            'Utils/draw_label.py': 'src/utils/visualization/draw_label.py',
            'Utils/draw_radar.py': 'src/utils/visualization/draw_radar.py',
            'Utils/extract_460.py': 'src/utils/data_io/extract_460.py',
            'Utils/extract_data.py': 'src/utils/data_io/extract_data.py',
            'Utils/generate_json.py': 'src/utils/data_io/generate_json.py',
            'Utils/load_data.py': 'src/utils/data_io/load_data.py',
            'Utils/mat_tool.py': 'src/utils/data_io/mat_tool.py',
            'Utils/merge_json.py': 'src/utils/data_io/merge_json.py',
            'Utils/merge_txt.py': 'src/utils/data_io/merge_txt.py',
            'Utils/modify_xlsx.py': 'src/utils/file_operations/modify_xlsx.py',
            'Utils/plot_result.py': 'src/utils/visualization/plot_result.py',
            'Utils/read_mat.py': 'src/utils/data_io/read_mat.py',
            'Utils/read_matrix.py': 'src/utils/data_io/read_matrix.py',
            'Utils/read_npz.py': 'src/utils/data_io/read_npz.py',
            'Utils/remove_txt_name.py': 'src/utils/file_operations/remove_txt_name.py',
            'Utils/resize.py': 'src/utils/file_operations/resize.py',
            'Utils/restore_matrix.py': 'src/utils/data_io/restore_matrix.py',
            'Utils/spectrum_2_tsyF.py': 'src/utils/data_io/spectrum_2_tsyf.py',
            'Utils/txt_2_xlsx.py': 'src/utils/file_operations/txt_2_xlsx.py',
            
            # æ¨¡å‹æ¼”ç¤º
            'model_demo/': 'notebooks/demos/',
            
            # æ ¹ç›®å½•æ–‡ä»¶
            'demo.py': 'notebooks/exploration/demo.py',
            'add_noise.py': 'src/preprocessing/add_noise.py',
        }
    
    def create_directory_structure(self, structure, base_path=None):
        """åˆ›å»ºç›®å½•ç»“æ„"""
        if base_path is None:
            base_path = self.project_root
        
        for name, subdirs in structure.items():
            dir_path = base_path / name
            dir_path.mkdir(exist_ok=True)
            self.log(f"åˆ›å»ºç›®å½•: {dir_path}")
            
            if subdirs:
                self.create_directory_structure(subdirs, dir_path)
    
    def copy_file_with_rename(self, src_path, dest_path):
        """å¤åˆ¶å¹¶é‡å‘½åæ–‡ä»¶"""
        try:
            src = self.project_root / src_path
            dest = self.project_root / dest_path
            
            if src.exists():
                dest.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(src, dest)
                self.log(f"å¤åˆ¶æ–‡ä»¶: {src_path} -> {dest_path}")
                return True
            else:
                self.log(f"æºæ–‡ä»¶ä¸å­˜åœ¨: {src_path}")
                return False
        except Exception as e:
            self.log(f"å¤åˆ¶æ–‡ä»¶å¤±è´¥ {src_path}: {str(e)}")
            return False
    
    def create_init_files(self, directory):
        """åˆ›å»º__init__.pyæ–‡ä»¶"""
        for root, dirs, files in os.walk(directory):
            # è·³è¿‡ç‰¹å®šç›®å½•
            dirs[:] = [d for d in dirs if d not in {'.git', '__pycache__', '.venv', 'dataset', 'dataset_classify'}]
            
            root_path = Path(root)
            if root_path.name in {'src', 'utils', 'classification', 'regression', 'augmentation', 'preprocessing', 'ui', 'tests', 'scripts'}:
                init_file = root_path / '__init__.py'
                if not init_file.exists():
                    init_file.write_text('"""Package initialization file."""\n')
                    self.log(f"åˆ›å»º __init__.py: {init_file}")
    
    def restructure_project(self):
        """æ‰§è¡Œé¡¹ç›®é‡æ„"""
        self.log("å¼€å§‹é¡¹ç›®é‡æ„...")
        
        # 1. åˆ›å»ºå¤‡ä»½
        if not self.create_backup():
            self.log("å¤‡ä»½å¤±è´¥ï¼Œåœæ­¢é‡æ„")
            return False
        
        # 2. åˆ›å»ºæ–°ç›®å½•ç»“æ„
        self.log("åˆ›å»ºæ–°ç›®å½•ç»“æ„...")
        new_structure = self.get_new_structure()
        self.create_directory_structure(new_structure)
        
        # 3. ç§»åŠ¨å’Œé‡å‘½åæ–‡ä»¶
        self.log("ç§»åŠ¨å’Œé‡å‘½åæ–‡ä»¶...")
        file_mapping = self.get_file_mapping()
        success_count = 0
        total_count = len(file_mapping)
        
        for src, dest in file_mapping.items():
            if self.copy_file_with_rename(src, dest):
                success_count += 1
        
        self.log(f"æ–‡ä»¶ç§»åŠ¨å®Œæˆ: {success_count}/{total_count}")
        
        # 4. åˆ›å»º__init__.pyæ–‡ä»¶
        self.log("åˆ›å»º__init__.pyæ–‡ä»¶...")
        self.create_init_files(self.project_root / 'src')
        
        # 5. åˆ›å»ºé…ç½®æ–‡ä»¶
        self.create_requirements_txt()
        self.create_gitignore()
        self.create_readme()
        
        self.log("é¡¹ç›®é‡æ„å®Œæˆï¼")
        return True
    
    def create_requirements_txt(self):
        """åˆ›å»ºrequirements.txtæ–‡ä»¶"""
        requirements = [
            "numpy>=1.21.0",
            "pandas>=1.3.0",
            "matplotlib>=3.4.0",
            "seaborn>=0.11.0",
            "scikit-learn>=1.0.0",
            "torch>=1.9.0",
            "torchvision>=0.10.0",
            "opencv-python>=4.5.0",
            "scipy>=1.7.0",
            "tqdm>=4.62.0",
            "jupyter>=1.0.0",
            "pytest>=6.2.0"
        ]
        
        req_file = self.project_root / 'requirements.txt'
        req_file.write_text('\n'.join(requirements) + '\n')
        self.log(f"åˆ›å»º requirements.txt")
    
    def create_gitignore(self):
        """åˆ›å»º.gitignoreæ–‡ä»¶"""
        gitignore_content = """# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
.venv/
venv/
ENV/

# IDE
.vscode/
.idea/
*.swp
*.swo

# Data
dataset/
dataset_classify/
dataset_result/
*.mat
*.npz
*.pkl

# Logs
logs/
*.log

# Results
results/
backup_*/

# OS
.DS_Store
Thumbs.db
"""
        gitignore_file = self.project_root / '.gitignore'
        gitignore_file.write_text(gitignore_content)
        self.log("åˆ›å»º .gitignore")
    
    def create_readme(self):
        """åˆ›å»ºREADME.mdæ–‡ä»¶"""
        readme_content = """# TsyF Spectrum Classification Project

## é¡¹ç›®ç»“æ„

```
â”œâ”€â”€ src/                    # æºä»£ç 
â”‚   â”œâ”€â”€ utils/             # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ classification/    # åˆ†ç±»æ¨¡å—
â”‚   â”œâ”€â”€ regression/        # å›å½’æ¨¡å—
â”‚   â”œâ”€â”€ augmentation/      # æ•°æ®å¢å¼º
â”‚   â”œâ”€â”€ preprocessing/     # æ•°æ®é¢„å¤„ç†
â”‚   â””â”€â”€ ui/               # ç”¨æˆ·ç•Œé¢
â”œâ”€â”€ notebooks/             # Jupyter notebooks
â”œâ”€â”€ tests/                # æµ‹è¯•ä»£ç 
â”œâ”€â”€ scripts/              # è„šæœ¬æ–‡ä»¶
â”œâ”€â”€ configs/              # é…ç½®æ–‡ä»¶
â””â”€â”€ docs/                 # æ–‡æ¡£

```

## å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

## ä½¿ç”¨è¯´æ˜

1. æ•°æ®é¢„å¤„ç†ï¼šä½¿ç”¨ `src/preprocessing/` ä¸­çš„è„šæœ¬
2. æ¨¡å‹è®­ç»ƒï¼šä½¿ç”¨ `scripts/training/` ä¸­çš„è„šæœ¬
3. æ¨¡å‹è¯„ä¼°ï¼šä½¿ç”¨ `scripts/evaluation/` ä¸­çš„è„šæœ¬

## é‡æ„è¯´æ˜

æœ¬é¡¹ç›®å·²å®Œæˆç»“æ„é‡æ„ï¼Œä¸»è¦æ”¹è¿›ï¼š
- æ¨¡å—åŒ–çš„ä»£ç ç»„ç»‡
- æ ‡å‡†åŒ–çš„æ–‡ä»¶å‘½å
- æ¸…æ™°çš„ç›®å½•ç»“æ„
- å®Œæ•´çš„æµ‹è¯•æ¡†æ¶
"""
        readme_file = self.project_root / 'README.md'
        readme_file.write_text(readme_content)
        self.log("åˆ›å»º README.md")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ ä¿®å¤ç‰ˆé¡¹ç›®é‡æ„å·¥å…·")
    print("=" * 50)
    
    restructurer = FixedProjectRestructurer()
    
    # ç¡®è®¤æ‰§è¡Œ
    response = input("æ˜¯å¦å¼€å§‹æ‰§è¡Œä¿®å¤ç‰ˆé‡æ„ï¼Ÿ(y/N): ")
    if response.lower() != 'y':
        print("âŒ æ“ä½œå·²å–æ¶ˆ")
        return 1
    
    # æ‰§è¡Œé‡æ„
    if restructurer.restructure_project():
        print("\nâœ… é‡æ„æˆåŠŸå®Œæˆï¼")
        print(f"ğŸ“ å¤‡ä»½ä½ç½®: {restructurer.backup_dir}")
        print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {restructurer.log_file}")
        return 0
    else:
        print("\nâŒ é‡æ„å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—")
        return 1

if __name__ == "__main__":
    sys.exit(main())
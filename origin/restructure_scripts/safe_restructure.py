#!/usr/bin/env python3
"""
å®‰å…¨ç‰ˆæœ¬çš„é¡¹ç›®é‡æ„è„šæœ¬
é¿å…é€’å½’å¤‡ä»½å’Œå…¶ä»–æ½œåœ¨é—®é¢˜
"""
import os
import shutil
import sys
from pathlib import Path
from datetime import datetime
import json

class SafeProjectRestructurer:
    def __init__(self, project_root=None):
        self.project_root = Path(project_root) if project_root else Path.cwd()
        # åœ¨é¡¹ç›®å†…éƒ¨åˆ›å»ºå¤‡ä»½ç›®å½•
        self.backup_dir = self.project_root / f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.log_file = self.project_root / "restructure.log"
        
    def log(self, message):
        """è®°å½•æ—¥å¿—"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_message = f"[{timestamp}] {message}"
        print(log_message)
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_message + '\n')
    
    def create_backup(self):
        """åˆ›å»ºé¡¹ç›®å¤‡ä»½ï¼ˆä»…ä»£ç æ–‡ä»¶ï¼Œé¿å…é€’å½’ï¼‰"""
        self.log("å¼€å§‹åˆ›å»ºé¡¹ç›®å¤‡ä»½...")
        
        # è¦æ’é™¤çš„ç›®å½•åç§°ï¼ˆå®Œå…¨åŒ¹é…ï¼‰
        exclude_dirs = {
            'dataset', 'dataset_classify', '.venv', '__pycache__', 
            'logs', 'results', 'dataset_result', '.git', '.idea'
        }
        exclude_extensions = {'.pyc', '.pyo', '.log'}
        
        try:
            # ç¡®ä¿å¤‡ä»½ç›®å½•ä¸å­˜åœ¨ï¼Œé¿å…é€’å½’
            if self.backup_dir.exists():
                self.log(f"å¤‡ä»½ç›®å½•å·²å­˜åœ¨ï¼Œåˆ é™¤æ—§å¤‡ä»½: {self.backup_dir}")
                shutil.rmtree(self.backup_dir)
            
            self.backup_dir.mkdir(exist_ok=True)
            
            def should_exclude(path_relative):
                """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤æŸä¸ªè·¯å¾„"""
                path_parts = path_relative.parts
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«æ’é™¤çš„ç›®å½•
                for part in path_parts:
                    if part in exclude_dirs:
                        return True
                    # æ’é™¤æ‰€æœ‰ä»¥backup_å¼€å¤´çš„ç›®å½•
                    if part.startswith('backup_'):
                        return True
                
                # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
                if path_relative.suffix in exclude_extensions:
                    return True
                    
                return False
            
            # å¤åˆ¶æ–‡ä»¶
            copied_count = 0
            skipped_count = 0
            
            # åªéå†ç›´æ¥å­é¡¹ï¼Œé¿å…æ·±åº¦é€’å½’é—®é¢˜
            def copy_directory(src_dir, dest_dir, level=0):
                nonlocal copied_count, skipped_count
                
                if level > 10:  # é˜²æ­¢è¿‡æ·±é€’å½’
                    self.log(f"è­¦å‘Šï¼šç›®å½•å±‚çº§è¿‡æ·±ï¼Œè·³è¿‡: {src_dir}")
                    return
                
                for item in src_dir.iterdir():
                    try:
                        rel_path = item.relative_to(self.project_root)
                        
                        if should_exclude(rel_path):
                            skipped_count += 1
                            continue
                        
                        dest_path = dest_dir / rel_path.name
                        
                        if item.is_file():
                            # å¤åˆ¶æ–‡ä»¶
                            dest_path.parent.mkdir(parents=True, exist_ok=True)
                            shutil.copy2(item, dest_path)
                            copied_count += 1
                        elif item.is_dir():
                            # é€’å½’å¤åˆ¶ç›®å½•
                            dest_path.mkdir(exist_ok=True)
                            copy_directory(item, dest_path, level + 1)
                            
                    except Exception as e:
                        self.log(f"å¤åˆ¶é¡¹ç›®æ—¶å‡ºé”™ {item}: {str(e)}")
                        skipped_count += 1
            
            # å¼€å§‹å¤åˆ¶
            copy_directory(self.project_root, self.backup_dir)
            
            self.log(f"å¤‡ä»½åˆ›å»ºæˆåŠŸ: {self.backup_dir}")
            self.log(f"å…±å¤åˆ¶ {copied_count} ä¸ªæ–‡ä»¶ï¼Œè·³è¿‡ {skipped_count} ä¸ªé¡¹ç›®")
            return True
            
        except Exception as e:
            self.log(f"å¤‡ä»½åˆ›å»ºå¼‚å¸¸: {str(e)}")
            return False
    
    def preview_changes(self):
        """é¢„è§ˆå°†è¦è¿›è¡Œçš„æ›´æ”¹"""
        self.log("é¢„è§ˆé‡æ„æ›´æ”¹...")
        
        file_mapping = self.get_file_mapping()
        
        print("\nğŸ“‹ å°†è¦è¿›è¡Œçš„æ–‡ä»¶ç§»åŠ¨:")
        print("=" * 60)
        
        existing_files = []
        missing_files = []
        
        for src, dest in file_mapping.items():
            src_path = self.project_root / src
            if src_path.exists():
                existing_files.append((src, dest))
                print(f"âœ… {src} -> {dest}")
            else:
                missing_files.append(src)
                print(f"âŒ {src} (æ–‡ä»¶ä¸å­˜åœ¨)")
        
        print(f"\nğŸ“Š ç»Ÿè®¡:")
        print(f"  - å¯ç§»åŠ¨æ–‡ä»¶: {len(existing_files)}")
        print(f"  - ç¼ºå¤±æ–‡ä»¶: {len(missing_files)}")
        
        if missing_files:
            print(f"\nâš ï¸ ä»¥ä¸‹æ–‡ä»¶ä¸å­˜åœ¨:")
            for file in missing_files:
                print(f"  - {file}")
        
        return len(existing_files), len(missing_files)
    
    def get_new_structure(self):
        """å®šä¹‰æ–°çš„ç›®å½•ç»“æ„"""
        return {
            'src': {
                'utils': {
                    'data_io': {},
                    'visualization': {},
                    'metrics': {},
                    'file_operations': {}
                },
                'classification': {
                    'models': {
                        'demo': {}
                    },
                    'utils': {}
                },
                'regression': {
                    'models': {},
                    'training': {},
                    'utils': {}
                },
                'augmentation': {},
                'preprocessing': {},
                'ui': {}
            },
            'notebooks': {
                'exploration': {},
                'experiments': {},
                'demos': {}
            },
            'tests': {
                'test_classification': {},
                'test_regression': {},
                'test_utils': {}
            },
            'scripts': {
                'training': {},
                'evaluation': {},
                'data_processing': {}
            },
            'configs': {},
            'docs': {}
        }
    
    def get_file_mapping(self):
        """å®šä¹‰æ–‡ä»¶æ˜ å°„å…³ç³»"""
        return {
            # å›å½’æ¨¡å—
            'regression/model/': 'src/regression/models/',
            'regression/training/': 'src/regression/training/',
            'regression/utils/': 'src/regression/utils/',
            'regression/run_training.py': 'scripts/training/run_regression_training.py',
            'regression/batch_run.py': 'scripts/training/batch_regression_run.py',
            
            # åˆ†ç±»æ¨¡å—
            'classfication/model/': 'src/classification/models/',
            'classfication/classify_model_demo/': 'src/classification/models/demo/',
            'classfication/Utils/': 'src/classification/utils/',
            
            # æ•°æ®å¢å¼º
            'augmentation/': 'src/augmentation/',
            
            # é¢„å¤„ç†
            'preprocess/': 'src/preprocessing/',
            
            # UI
            'UI_version/': 'src/ui/',
            
            # å·¥å…·ç±» - æ•°æ®IO
            'Utils/extract_460.py': 'src/utils/data_io/extract_460.py',
            'Utils/extract_data.py': 'src/utils/data_io/extract_data.py',
            'Utils/generate_json.py': 'src/utils/data_io/generate_json.py',
            'Utils/load_data.py': 'src/utils/data_io/load_data.py',
            'Utils/mat_tool.py': 'src/utils/data_io/mat_tool.py',
            'Utils/merge_json.py': 'src/utils/data_io/merge_json.py',
            'Utils/merge_txt.py': 'src/utils/data_io/merge_txt.py',
            'Utils/read_mat.py': 'src/utils/data_io/read_mat.py',
            'Utils/read_matrix.py': 'src/utils/data_io/read_matrix.py',
            'Utils/read_npz.py': 'src/utils/data_io/read_npz.py',
            'Utils/restore_matrix.py': 'src/utils/data_io/restore_matrix.py',
            'Utils/spectrum_2_tsyF.py': 'src/utils/data_io/spectrum_2_tsyf.py',
            
            # å·¥å…·ç±» - å¯è§†åŒ–
            'Utils/draw_2D_spectrum.py': 'src/utils/visualization/draw_2d_spectrum.py',
            'Utils/draw_2D_spectrum_xlsx.py': 'src/utils/visualization/draw_2d_spectrum_xlsx.py',
            'Utils/draw_contour.py': 'src/utils/visualization/draw_contour.py',
            'Utils/draw_label.py': 'src/utils/visualization/draw_label.py',
            'Utils/draw_radar.py': 'src/utils/visualization/draw_radar.py',
            'Utils/plot_result.py': 'src/utils/visualization/plot_result.py',
            
            # å·¥å…·ç±» - æŒ‡æ ‡è®¡ç®—
            'Utils/compute_pearson.py': 'src/utils/metrics/compute_pearson.py',
            'Utils/compute_relative_error.py': 'src/utils/metrics/compute_relative_error.py',
            'Utils/compute_similarity.py': 'src/utils/metrics/compute_similarity.py',
            'Utils/cosine_similarity.py': 'src/utils/metrics/cosine_similarity.py',
            
            # å·¥å…·ç±» - æ–‡ä»¶æ“ä½œ
            'Utils/batch_resize.py': 'src/utils/file_operations/batch_resize.py',
            'Utils/modify_xlsx.py': 'src/utils/file_operations/modify_xlsx.py',
            'Utils/remove_txt_name.py': 'src/utils/file_operations/remove_txt_name.py',
            'Utils/resize.py': 'src/utils/file_operations/resize.py',
            'Utils/txt_2_xlsx.py': 'src/utils/file_operations/txt_2_xlsx.py',
            
            # è„šæœ¬
            'Utils/batch_test.py': 'scripts/evaluation/batch_test.py',
            
            # ç¬”è®°æœ¬
            'model_demo/': 'notebooks/demos/',
            'demo.py': 'notebooks/exploration/demo.py',
            
            # é¢„å¤„ç†
            'add_noise.py': 'src/preprocessing/add_noise.py',
        }
    
    def restructure_project(self):
        """æ‰§è¡Œé¡¹ç›®é‡æ„"""
        self.log("å¼€å§‹å®‰å…¨é¡¹ç›®é‡æ„...")
        
        # 1. é¢„è§ˆæ›´æ”¹
        existing_count, missing_count = self.preview_changes()
        
        if missing_count > 0:
            response = input(f"\nå‘ç° {missing_count} ä¸ªæ–‡ä»¶ç¼ºå¤±ï¼Œæ˜¯å¦ç»§ç»­ï¼Ÿ(y/N): ")
            if response.lower() != 'y':
                self.log("ç”¨æˆ·å–æ¶ˆé‡æ„")
                return False
        
        # 2. åˆ›å»ºå¤‡ä»½
        if not self.create_backup():
            self.log("å¤‡ä»½å¤±è´¥ï¼Œåœæ­¢é‡æ„")
            return False
        
        # 3. åˆ›å»ºæ–°ç›®å½•ç»“æ„
        self.log("åˆ›å»ºæ–°ç›®å½•ç»“æ„...")
        new_structure = self.get_new_structure()
        self.create_directory_structure(new_structure)
        
        # 4. ç§»åŠ¨å’Œé‡å‘½åæ–‡ä»¶
        self.log("ç§»åŠ¨å’Œé‡å‘½åæ–‡ä»¶...")
        file_mapping = self.get_file_mapping()
        success_count = 0
        
        for src, dest in file_mapping.items():
            if self.copy_file_with_rename(src, dest):
                success_count += 1
        
        self.log(f"æ–‡ä»¶ç§»åŠ¨å®Œæˆ: {success_count}/{len(file_mapping)}")
        
        # 5. åˆ›å»º__init__.pyæ–‡ä»¶
        self.log("åˆ›å»º__init__.pyæ–‡ä»¶...")
        self.create_init_files(self.project_root / 'src')
        
        # 6. åˆ›å»ºé…ç½®æ–‡ä»¶
        self.create_requirements_txt()
        self.create_gitignore()
        self.create_readme()
        
        self.log("å®‰å…¨é¡¹ç›®é‡æ„å®Œæˆï¼")
        return True
    
    def create_directory_structure(self, structure, base_path=None):
        """åˆ›å»ºç›®å½•ç»“æ„"""
        if base_path is None:
            base_path = self.project_root
        
        for name, subdirs in structure.items():
            dir_path = base_path / name
            dir_path.mkdir(exist_ok=True)
            self.log(f"åˆ›å»ºç›®å½•: {dir_path}")
            
            if subdirs:
                self.create_directory_structure(subdirs, dir_path)
    
    def copy_file_with_rename(self, src_path, dest_path):
        """å¤åˆ¶å¹¶é‡å‘½åæ–‡ä»¶"""
        try:
            src = self.project_root / src_path
            dest = self.project_root / dest_path
            
            if src.exists():
                dest.parent.mkdir(parents=True, exist_ok=True)
                if src.is_dir():
                    if dest.exists():
                        shutil.rmtree(dest)
                    shutil.copytree(src, dest)
                else:
                    shutil.copy2(src, dest)
                self.log(f"å¤åˆ¶: {src_path} -> {dest_path}")
                return True
            else:
                self.log(f"æºæ–‡ä»¶ä¸å­˜åœ¨: {src_path}")
                return False
        except Exception as e:
            self.log(f"å¤åˆ¶æ–‡ä»¶å¤±è´¥ {src_path}: {str(e)}")
            return False
    
    def create_init_files(self, directory):
        """åˆ›å»º__init__.pyæ–‡ä»¶"""
        for root, dirs, files in os.walk(directory):
            # è·³è¿‡ç‰¹å®šç›®å½•
            dirs[:] = [d for d in dirs if d not in {'.git', '__pycache__', '.venv', 'dataset', 'dataset_classify'} and not d.startswith('backup_')]
            
            root_path = Path(root)
            if root_path.name in {'src', 'utils', 'classification', 'regression', 'augmentation', 'preprocessing', 'ui', 'tests', 'scripts'}:
                init_file = root_path / '__init__.py'
                if not init_file.exists():
                    init_file.write_text('"""Package initialization file."""\n')
                    self.log(f"åˆ›å»º __init__.py: {init_file}")
    
    def create_requirements_txt(self):
        """åˆ›å»ºrequirements.txtæ–‡ä»¶"""
        requirements = [
            "numpy>=1.21.0",
            "pandas>=1.3.0", 
            "matplotlib>=3.4.0",
            "seaborn>=0.11.0",
            "scikit-learn>=1.0.0",
            "torch>=1.9.0",
            "torchvision>=0.10.0",
            "opencv-python>=4.5.0",
            "scipy>=1.7.0",
            "tqdm>=4.62.0",
            "jupyter>=1.0.0",
            "pytest>=6.2.0"
        ]
        
        req_file = self.project_root / 'requirements.txt'
        req_file.write_text('\n'.join(requirements) + '\n')
        self.log(f"åˆ›å»º requirements.txt")
    
    def create_gitignore(self):
        """åˆ›å»º.gitignoreæ–‡ä»¶"""
        gitignore_content = """# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
.venv/
venv/
ENV/

# IDE
.vscode/
.idea/
*.swp
*.swo

# Data
dataset/
dataset_classify/
dataset_result/
*.mat
*.npz
*.pkl

# Logs
logs/
*.log

# Results
results/
backup_*/

# OS
.DS_Store
Thumbs.db
"""
        gitignore_file = self.project_root / '.gitignore'
        gitignore_file.write_text(gitignore_content)
        self.log("åˆ›å»º .gitignore")
    
    def create_readme(self):
        """åˆ›å»ºREADME.mdæ–‡ä»¶"""
        readme_content = """# TsyF Spectrum Classification Project

## é¡¹ç›®ç»“æ„

```
â”œâ”€â”€ src/                    # æºä»£ç 
â”‚   â”œâ”€â”€ utils/             # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ classification/    # åˆ†ç±»æ¨¡å—
â”‚   â”œâ”€â”€ regression/        # å›å½’æ¨¡å—
â”‚   â”œâ”€â”€ augmentation/      # æ•°æ®å¢å¼º
â”‚   â”œâ”€â”€ preprocessing/     # æ•°æ®é¢„å¤„ç†
â”‚   â””â”€â”€ ui/               # ç”¨æˆ·ç•Œé¢
â”œâ”€â”€ notebooks/             # Jupyter notebooks
â”œâ”€â”€ tests/                # æµ‹è¯•ä»£ç 
â”œâ”€â”€ scripts/              # è„šæœ¬æ–‡ä»¶
â”œâ”€â”€ configs/              # é…ç½®æ–‡ä»¶
â””â”€â”€ docs/                 # æ–‡æ¡£
```

## å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

## ä½¿ç”¨è¯´æ˜

1. æ•°æ®é¢„å¤„ç†ï¼šä½¿ç”¨ `src/preprocessing/` ä¸­çš„è„šæœ¬
2. æ¨¡å‹è®­ç»ƒï¼šä½¿ç”¨ `scripts/training/` ä¸­çš„è„šæœ¬
3. æ¨¡å‹è¯„ä¼°ï¼šä½¿ç”¨ `scripts/evaluation/` ä¸­çš„è„šæœ¬

## é‡æ„è¯´æ˜

æœ¬é¡¹ç›®å·²å®Œæˆå®‰å…¨é‡æ„ï¼Œä¸»è¦æ”¹è¿›ï¼š
- æ¨¡å—åŒ–çš„ä»£ç ç»„ç»‡
- æ ‡å‡†åŒ–çš„æ–‡ä»¶å‘½å
- æ¸…æ™°çš„ç›®å½•ç»“æ„
- å®Œæ•´çš„æµ‹è¯•æ¡†æ¶
- é¿å…é€’å½’å¤‡ä»½é—®é¢˜
"""
        readme_file = self.project_root / 'README.md'
        readme_file.write_text(readme_content)
        self.log("åˆ›å»º README.md")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ›¡ï¸ å®‰å…¨ç‰ˆé¡¹ç›®é‡æ„å·¥å…·")
    print("=" * 50)
    print("ç‰¹æ€§:")
    print("- é¿å…é€’å½’å¤‡ä»½")
    print("- é¢„è§ˆæ›´æ”¹")
    print("- è¯¦ç»†æ—¥å¿—")
    print("- å®‰å…¨æ£€æŸ¥")
    print("=" * 50)
    
    restructurer = SafeProjectRestructurer()
    
    # ç¡®è®¤æ‰§è¡Œ
    response = input("\næ˜¯å¦å¼€å§‹æ‰§è¡Œå®‰å…¨é‡æ„ï¼Ÿ(y/N): ")
    if response.lower() != 'y':
        print("âŒ æ“ä½œå·²å–æ¶ˆ")
        return 1
    
    # æ‰§è¡Œé‡æ„
    if restructurer.restructure_project():
        print("\nâœ… å®‰å…¨é‡æ„æˆåŠŸå®Œæˆï¼")
        print(f"ğŸ“ å¤‡ä»½ä½ç½®: {restructurer.backup_dir}")
        print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {restructurer.log_file}")
        return 0
    else:
        print("\nâŒ é‡æ„å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—")
        return 1

if __name__ == "__main__":
    sys.exit(main())
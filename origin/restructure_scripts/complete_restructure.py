#!/usr/bin/env python3
"""
å®Œæ•´çš„é¡¹ç›®é‡æ„è„šæœ¬
åŒ…å«å¤‡ä»½ã€é‡æ„ã€éªŒè¯ç­‰åŠŸèƒ½
"""
import os
import shutil
import subprocess
import sys
from pathlib import Path
from datetime import datetime
import json

class ProjectRestructurer:
    def __init__(self, project_root=None):
        self.project_root = Path(project_root) if project_root else Path.cwd()
        self.backup_dir = self.project_root.parent / f"TsyFSpectrumClassify_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.log_file = self.project_root / "restructure.log"
        
    def log(self, message):
        """è®°å½•æ—¥å¿—"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_message = f"[{timestamp}] {message}"
        print(log_message)
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_message + '\n')
    
    def create_backup(self):
        """åˆ›å»ºé¡¹ç›®å¤‡ä»½ï¼ˆä»…ä»£ç æ–‡ä»¶ï¼‰"""
        self.log("å¼€å§‹åˆ›å»ºé¡¹ç›®å¤‡ä»½...")
        
        # è¦æ’é™¤çš„ç›®å½•å’Œæ–‡ä»¶
        exclude_patterns = [
            'dataset/',
            'dataset_classify/',
            '.venv/',
            '__pycache__/',
            '*.pyc',
            '*.pyo',
            'logs/',
            'results/',
            'dataset_result/',
            '.git/',
            '*.log'
        ]
        
        try:
            # ä½¿ç”¨rsyncåˆ›å»ºå¤‡ä»½
            cmd = ['rsync', '-av'] + [f'--exclude={pattern}' for pattern in exclude_patterns]
            cmd.extend([str(self.project_root) + '/', str(self.backup_dir) + '/'])
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                self.log(f"å¤‡ä»½åˆ›å»ºæˆåŠŸ: {self.backup_dir}")
                return True
            else:
                self.log(f"å¤‡ä»½åˆ›å»ºå¤±è´¥: {result.stderr}")
                return False
        except Exception as e:
            self.log(f"å¤‡ä»½åˆ›å»ºå¼‚å¸¸: {str(e)}")
            return False
    
    def get_new_structure(self):
        """å®šä¹‰æ–°çš„ç›®å½•ç»“æ„"""
        return {
            'data': {
                'raw': {},
                'processed': {},
                'augmented': {},
                'results': {}
            },
            'src': {
                'utils': {
                    'data_io': {},
                    'visualization': {},
                    'metrics': {},
                    'file_operations': {}
                },
                'classification': {
                    'models': {
                        'demo': {}
                    },
                    'utils': {}
                },
                'regression': {
                    'models': {},
                    'training': {},
                    'utils': {}
                },
                'augmentation': {},
                'preprocessing': {},
                'ui': {}
            },
            'notebooks': {
                'exploration': {},
                'experiments': {},
                'demos': {}
            },
            'tests': {
                'test_classification': {},
                'test_regression': {},
                'test_utils': {}
            },
            'configs': {
                'model_configs': {},
                'data_configs': {},
                'training_configs': {}
            },
            'scripts': {},
            'docs': {}
        }
    
    def get_file_mapping(self):
        """å®šä¹‰æ–‡ä»¶æ˜ å°„å…³ç³»"""
        return {
            # Utilsç›®å½• - æ•°æ®IO
            'Utils/read_mat.py': 'src/utils/data_io/mat_reader.py',
            'Utils/read)mat.py': 'src/utils/data_io/mat_reader_alt.py',
            'Utils/read_matrix.py': 'src/utils/data_io/matrix_reader.py',
            'Utils/read_npz.py': 'src/utils/data_io/npz_reader.py',
            'Utils/load_data.py': 'src/utils/data_io/data_loader.py',
            'Utils/extract_data.py': 'src/utils/data_io/data_extractor.py',
            'Utils/extract_460.py': 'src/utils/data_io/extract_460.py',
            'Utils/mat_tool.py': 'src/utils/data_io/mat_tool.py',
            'Utils/generate_json.py': 'src/utils/data_io/json_generator.py',
            
            # Utilsç›®å½• - å¯è§†åŒ–
            'Utils/draw_2D_spectrum.py': 'src/utils/visualization/spectrum_plotter.py',
            'Utils/draw_2D_spectrum_xlsx.py': 'src/utils/visualization/spectrum_xlsx_plotter.py',
            'Utils/draw_contour.py': 'src/utils/visualization/contour_plotter.py',
            'Utils/draw_radar.py': 'src/utils/visualization/radar_plotter.py',
            'Utils/draw_label.py': 'src/utils/visualization/label_drawer.py',
            'Utils/plot_result.py': 'src/utils/visualization/result_plotter.py',
            
            # Utilsç›®å½• - è¯„ä¼°æŒ‡æ ‡
            'Utils/compute_similarity.py': 'src/utils/metrics/similarity_calculator.py',
            'Utils/compute_pearson.py': 'src/utils/metrics/pearson_calculator.py',
            'Utils/compute_relative_error.py': 'src/utils/metrics/relative_error.py',
            'Utils/cosine_similarity.py': 'src/utils/metrics/cosine_similarity.py',
            
            # Utilsç›®å½• - æ–‡ä»¶æ“ä½œ
            'Utils/batch_resize.py': 'src/utils/file_operations/batch_resizer.py',
            'Utils/resize.py': 'src/utils/file_operations/resizer.py',
            'Utils/merge_json.py': 'src/utils/file_operations/json_merger.py',
            'Utils/merge_txt.py': 'src/utils/file_operations/txt_merger.py',
            'Utils/txt_2_xlsx.py': 'src/utils/file_operations/txt_to_xlsx.py',
            'Utils/modify_xlsx.py': 'src/utils/file_operations/xlsx_modifier.py',
            'Utils/remove_txt_name.py': 'src/utils/file_operations/name_processor.py',
            
            # é¢„å¤„ç†
            'Utils/restore_matrix.py': 'src/preprocessing/matrix_restorer.py',
            'Utils/spectrum_2_tsyF.py': 'src/preprocessing/spectrum_converter.py',
            'preprocess/ZScore_norm.py': 'src/preprocessing/zscore_normalizer.py',
            'preprocess/add_noise.py': 'src/preprocessing/noise_adder.py',
            'preprocess/augment_data.py': 'src/preprocessing/data_augmenter.py',
            'add_noise.py': 'src/preprocessing/noise_adder_main.py',
            
            # åˆ†ç±»æ¨¡å‹
            'classfication/model/2D_CNN1.py': 'src/classification/models/cnn_2d_v1.py',
            'classfication/model/KNN1.py': 'src/classification/models/knn_v1.py',
            'classfication/model/LSTM1.py': 'src/classification/models/lstm_v1.py',
            'classfication/model/RF1.py': 'src/classification/models/random_forest_v1.py',
            'classfication/model/Transformer1.py': 'src/classification/models/transformer_v1.py',
            'classfication/model/SimpleCNN.py': 'src/classification/models/simple_cnn.py',
            'classfication/model/SimpleLSTM.py': 'src/classification/models/simple_lstm.py',
            'classfication/model/SimpleTransformer.py': 'src/classification/models/simple_transformer.py',
            'classfication/model/GateNetWork.py': 'src/classification/models/gate_network.py',
            'classfication/model/vote_model.py': 'src/classification/models/vote_model.py',
            
            # åˆ†ç±»æ¨¡å‹æ¼”ç¤º
            'classfication/classify_model_demo/2D_CNN.py': 'src/classification/models/demo/cnn_2d_v2.py',
            'classfication/classify_model_demo/KNN.py': 'src/classification/models/demo/knn_v2.py',
            'classfication/classify_model_demo/Moe.py': 'src/classification/models/demo/moe.py',
            'model_demo/1D-CNN.py': 'src/classification/models/demo/cnn_1d.py',
            'model_demo/2D_CNN.py': 'src/classification/models/demo/cnn_2d_v3.py',
            'model_demo/KNN.py': 'src/classification/models/demo/knn_v3.py',
            'model_demo/LSTM.py': 'src/classification/models/demo/lstm.py',
            'model_demo/PLS-DA.py': 'src/classification/models/demo/pls_da.py',
            'model_demo/RandomForest.py': 'src/classification/models/demo/random_forest.py',
            'model_demo/Transformer.py': 'src/classification/models/demo/transformer_v2.py',
            'model_demo/Transformer_kimi.py': 'src/classification/models/demo/transformer_kimi.py',
            'model_demo/feature_engineering_and_CNN.py': 'src/classification/models/demo/feature_engineering_cnn.py',
            
            # åˆ†ç±»å·¥å…·
            'classfication/Utils/ImageDataset.py': 'src/classification/utils/image_dataset.py',
            'classfication/Utils/generate_category_json.py': 'src/classification/utils/category_generator.py',
            'classfication/Utils/plot.py': 'src/classification/utils/plot_utils.py',
            'classfication/Utils/read_matrix.py': 'src/classification/utils/matrix_reader.py',
            
            # å›å½’æ¨¡å‹
            'regression/model/DualSimpleCNN.py': 'src/regression/models/dual_simple_cnn.py',
            'regression/model/DualUNet.py': 'src/regression/models/dual_unet.py',
            'regression/model/DualUNet_co_encoder.py': 'src/regression/models/dual_unet_shared_encoder.py',
            'regression/model/FVGG11.py': 'src/regression/models/vgg11.py',
            'regression/model/ResNet18.py': 'src/regression/models/resnet18.py',
            'regression/model/UNet.py': 'src/regression/models/unet.py',
            
            # å›å½’è®­ç»ƒ
            'regression/training/CustomDataset.py': 'src/regression/training/custom_dataset.py',
            'regression/training/test_model.py': 'src/regression/training/test_model.py',
            'regression/training/train_model.py': 'src/regression/training/train_model.py',
            
            # å›å½’è„šæœ¬
            'regression/batch_run.py': 'scripts/batch_run_regression.py',
            'regression/run_training.py': 'scripts/run_regression_training.py',
            
            # æ•°æ®å¢å¼º
            'augmentation/GMM.py': 'src/augmentation/gmm.py',
            'augmentation/MixUp.py': 'src/augmentation/mixup.py',
            'augmentation/VAE.py': 'src/augmentation/vae.py',
            'augmentation/draw_contour.py': 'src/augmentation/contour_drawer.py',
            
            # UI
            'UI_version/draw_contour_ui.py': 'src/ui/contour_ui.py',
            
            # è„šæœ¬
            'demo.py': 'scripts/demo.py',
            'Utils/batch_test.py': 'scripts/batch_test.py',
            'Utils/test.py': 'scripts/test_utils.py',
            'Utils/temp.py': 'scripts/temp.py',
        }
    
    def create_directory_structure(self, structure, base_path=None):
        """åˆ›å»ºç›®å½•ç»“æ„"""
        if base_path is None:
            base_path = self.project_root
        
        for name, subdirs in structure.items():
            dir_path = base_path / name
            dir_path.mkdir(exist_ok=True)
            self.log(f"åˆ›å»ºç›®å½•: {dir_path}")
            
            if isinstance(subdirs, dict) and subdirs:
                self.create_directory_structure(subdirs, dir_path)
    
    def copy_file_with_rename(self, src_path, dest_path):
        """å¤åˆ¶å¹¶é‡å‘½åæ–‡ä»¶"""
        src_full = self.project_root / src_path
        dest_full = self.project_root / dest_path
        
        if not src_full.exists():
            self.log(f"æºæ–‡ä»¶ä¸å­˜åœ¨: {src_full}")
            return False
        
        # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
        dest_full.parent.mkdir(parents=True, exist_ok=True)
        
        try:
            shutil.copy2(src_full, dest_full)
            self.log(f"å¤åˆ¶æ–‡ä»¶: {src_path} -> {dest_path}")
            return True
        except Exception as e:
            self.log(f"å¤åˆ¶æ–‡ä»¶å¤±è´¥ {src_path}: {str(e)}")
            return False
    
    def create_init_files(self, directory):
        """åˆ›å»º__init__.pyæ–‡ä»¶"""
        for root, dirs, files in os.walk(directory):
            # è·³è¿‡æŸäº›ç›®å½•
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'logs', 'results']]
            
            root_path = Path(root)
            if root_path.name in ['src', 'utils', 'classification', 'regression', 'augmentation', 'preprocessing', 'ui', 'tests']:
                init_file = root_path / '__init__.py'
                if not init_file.exists():
                    init_file.touch()
                    self.log(f"åˆ›å»º__init__.py: {init_file}")
    
    def create_requirements_txt(self):
        """åˆ›å»ºrequirements.txtæ–‡ä»¶"""
        requirements = [
            "numpy>=1.21.0",
            "pandas>=1.3.0",
            "matplotlib>=3.4.0",
            "seaborn>=0.11.0",
            "scikit-learn>=1.0.0",
            "torch>=1.9.0",
            "torchvision>=0.10.0",
            "scipy>=1.7.0",
            "opencv-python>=4.5.0",
            "pillow>=8.3.0",
            "jupyter>=1.0.0",
            "tqdm>=4.62.0",
            "h5py>=3.3.0"
        ]
        
        req_file = self.project_root / 'requirements.txt'
        with open(req_file, 'w') as f:
            f.write('\n'.join(requirements))
        self.log(f"åˆ›å»ºrequirements.txt: {req_file}")
    
    def create_gitignore(self):
        """åˆ›å»º.gitignoreæ–‡ä»¶"""
        gitignore_content = """# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
.venv/
venv/
ENV/
env/

# IDE
.idea/
.vscode/
*.swp
*.swo

# Data files
data/
dataset/
dataset_classify/
*.mat
*.npz
*.h5

# Logs and results
logs/
results/
*.log

# OS
.DS_Store
Thumbs.db

# Jupyter Notebook
.ipynb_checkpoints

# Model files
*.pth
*.pkl
*.joblib
"""
        
        gitignore_file = self.project_root / '.gitignore'
        with open(gitignore_file, 'w') as f:
            f.write(gitignore_content)
        self.log(f"åˆ›å»º.gitignore: {gitignore_file}")
    
    def create_readme(self):
        """åˆ›å»ºREADME.mdæ–‡ä»¶"""
        readme_content = """# TsyF Spectrum Classification Project

## é¡¹ç›®ç®€ä»‹
è¿™æ˜¯ä¸€ä¸ªç”¨äºå…‰è°±åˆ†ç±»å’Œå›å½’åˆ†æçš„æœºå™¨å­¦ä¹ é¡¹ç›®ã€‚

## é¡¹ç›®ç»“æ„
```
â”œâ”€â”€ data/                   # æ•°æ®ç›®å½•
â”œâ”€â”€ src/                    # æºä»£ç 
â”‚   â”œâ”€â”€ classification/     # åˆ†ç±»æ¨¡å—
â”‚   â”œâ”€â”€ regression/         # å›å½’æ¨¡å—
â”‚   â”œâ”€â”€ utils/             # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ augmentation/      # æ•°æ®å¢å¼º
â”‚   â”œâ”€â”€ preprocessing/     # æ•°æ®é¢„å¤„ç†
â”‚   â””â”€â”€ ui/               # ç”¨æˆ·ç•Œé¢
â”œâ”€â”€ notebooks/             # Jupyter notebooks
â”œâ”€â”€ tests/                # æµ‹è¯•ä»£ç 
â”œâ”€â”€ configs/              # é…ç½®æ–‡ä»¶
â”œâ”€â”€ scripts/              # è„šæœ¬æ–‡ä»¶
â””â”€â”€ docs/                 # æ–‡æ¡£
```

## å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

## ä½¿ç”¨æ–¹æ³•
è¯¦ç»†ä½¿ç”¨æ–¹æ³•è¯·å‚è€ƒdocsç›®å½•ä¸‹çš„æ–‡æ¡£ã€‚

## è´¡çŒ®
æ¬¢è¿æäº¤Issueå’ŒPull Requestã€‚
"""
        
        readme_file = self.project_root / 'README.md'
        with open(readme_file, 'w', encoding='utf-8') as f:
            f.write(readme_content)
        self.log(f"åˆ›å»ºREADME.md: {readme_file}")
    
    def restructure_project(self):
        """æ‰§è¡Œå®Œæ•´çš„é¡¹ç›®é‡æ„"""
        self.log("å¼€å§‹é¡¹ç›®é‡æ„...")
        
        # 1. åˆ›å»ºå¤‡ä»½
        if not self.create_backup():
            self.log("å¤‡ä»½å¤±è´¥ï¼Œç»ˆæ­¢é‡æ„")
            return False
        
        # 2. åˆ›å»ºæ–°çš„ç›®å½•ç»“æ„
        self.log("åˆ›å»ºæ–°çš„ç›®å½•ç»“æ„...")
        structure = self.get_new_structure()
        self.create_directory_structure(structure)
        
        # 3. ç§»åŠ¨å’Œé‡å‘½åæ–‡ä»¶
        self.log("ç§»åŠ¨å’Œé‡å‘½åæ–‡ä»¶...")
        file_mapping = self.get_file_mapping()
        success_count = 0
        total_count = len(file_mapping)
        
        for src, dest in file_mapping.items():
            if self.copy_file_with_rename(src, dest):
                success_count += 1
        
        self.log(f"æ–‡ä»¶ç§»åŠ¨å®Œæˆ: {success_count}/{total_count}")
        
        # 4. åˆ›å»º__init__.pyæ–‡ä»¶
        self.log("åˆ›å»º__init__.pyæ–‡ä»¶...")
        self.create_init_files(self.project_root / 'src')
        self.create_init_files(self.project_root / 'tests')
        
        # 5. åˆ›å»ºé¡¹ç›®æ–‡ä»¶
        self.log("åˆ›å»ºé¡¹ç›®é…ç½®æ–‡ä»¶...")
        self.create_requirements_txt()
        self.create_gitignore()
        self.create_readme()
        
        self.log("é¡¹ç›®é‡æ„å®Œæˆ!")
        self.log(f"å¤‡ä»½ä½ç½®: {self.backup_dir}")
        self.log(f"æ—¥å¿—æ–‡ä»¶: {self.log_file}")
        
        return True
    
    def validate_restructure(self):
        """éªŒè¯é‡æ„ç»“æœ"""
        self.log("éªŒè¯é‡æ„ç»“æœ...")
        
        required_dirs = [
            'src/classification/models',
            'src/regression/models',
            'src/utils/data_io',
            'src/utils/visualization',
            'scripts',
            'configs'
        ]
        
        missing_dirs = []
        for dir_path in required_dirs:
            full_path = self.project_root / dir_path
            if not full_path.exists():
                missing_dirs.append(dir_path)
        
        if missing_dirs:
            self.log(f"ç¼ºå°‘ç›®å½•: {missing_dirs}")
            return False
        else:
            self.log("ç›®å½•ç»“æ„éªŒè¯é€šè¿‡")
            return True

def main():
    """ä¸»å‡½æ•°"""
    print("TsyF Spectrum Classification é¡¹ç›®é‡æ„å·¥å…·")
    print("=" * 50)
    
    # ç¡®è®¤æ“ä½œ
    response = input("æ˜¯å¦å¼€å§‹é‡æ„é¡¹ç›®ï¼Ÿè¿™å°†åˆ›å»ºå¤‡ä»½å¹¶é‡æ–°ç»„ç»‡æ–‡ä»¶ç»“æ„ (y/N): ")
    if response.lower() != 'y':
        print("æ“ä½œå·²å–æ¶ˆ")
        return
    
    # æ‰§è¡Œé‡æ„
    restructurer = ProjectRestructurer()
    
    try:
        if restructurer.restructure_project():
            if restructurer.validate_restructure():
                print("\nâœ… é¡¹ç›®é‡æ„æˆåŠŸå®Œæˆ!")
                print(f"ğŸ“ å¤‡ä»½ä½ç½®: {restructurer.backup_dir}")
                print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {restructurer.log_file}")
                print("\nä¸‹ä¸€æ­¥:")
                print("1. æ£€æŸ¥é‡æ„åçš„æ–‡ä»¶ç»“æ„")
                print("2. æ›´æ–°importè¯­å¥")
                print("3. è¿è¡Œæµ‹è¯•éªŒè¯åŠŸèƒ½")
            else:
                print("\nâš ï¸ é‡æ„å®Œæˆä½†éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
        else:
            print("\nâŒ é‡æ„å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
    except Exception as e:
        print(f"\nâŒ é‡æ„è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())